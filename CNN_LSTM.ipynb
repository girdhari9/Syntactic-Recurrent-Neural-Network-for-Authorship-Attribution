{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "I3t914ETStyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wI20cQwmSz6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize, sent_tokenize \n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "stop_words = set(stopwords.words('english')) \n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers import concatenate,CuDNNLSTM\n",
        "from keras import initializers\n",
        "from keras import backend as K\n",
        "import random\n",
        "\n",
        "from keras.layers import Dense, LSTM,Dropout, Activation,Bidirectional,Reshape,Permute,Multiply,Flatten,Lambda,Layer,TimeDistributed,CuDNNLSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8u-5fFr5amqy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def SentenceToPOS(sentences):\n",
        "    data = []\n",
        "    for sentence in sentences: \n",
        "        one_sentence_pos = [] \n",
        "        \n",
        "        wordsList = nltk.word_tokenize(sentence)\n",
        "        \n",
        "        wordsList = [w for w in wordsList if not w in stop_words]\n",
        "\n",
        "        tagged = nltk.pos_tag(wordsList)\n",
        "        \n",
        "        for val in tagged:\n",
        "            one_sentence_pos.append(val[1])\n",
        "        data.append(one_sentence_pos)\n",
        "    return data\n",
        "\n",
        "def Fianl_X_and_Y(novelPOS, novelLabel, sentenceSize):\n",
        "    i, X, Y = 0, [], []\n",
        "    for novel in novelPOS:\n",
        "        start, end = 0, sentenceSize\n",
        "        while(end <= len(novel)):\n",
        "            X.append(novel[start:end])\n",
        "            Y.append(novelLabel[i])\n",
        "            start = end\n",
        "            end += sentenceSize \n",
        "        i += 1\n",
        "    return X, Y\n",
        "\n",
        "def Get_X_and_Y_In_POS_Form(fullPath, sentenceSize):\n",
        "    filenameList = os.listdir(fullPath)\n",
        "    filenameList.sort()\n",
        "    \n",
        "    novelPOS, novelLabel, fileNumber = [], [], 1\n",
        "    for filename in filenameList:\n",
        "        print(fileNumber,\"/\",len(filenameList),\" Done\")\n",
        "        fileNumber += 1\n",
        "        Path = fullPath + filename\n",
        "        with open(Path, 'r') as f:\n",
        "            data = f.read().replace('\"\\n\"','').replace('\\n',' ').replace('- ','')\n",
        "            sentences = sent_tokenize(data)\n",
        "            POS = SentenceToPOS(sentences)\n",
        "            novelPOS.append(POS)\n",
        "            novelLabel.append(filename[8])\n",
        "    return Fianl_X_and_Y(novelPOS, novelLabel, sentenceSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5wr7ucjBUtYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Preprocessing Phase 1 : Fetching data\")\n",
        "print(\".....................................\")\n",
        "\n",
        "X, Y = Get_X_and_Y_In_POS_Form('/content/gdrive/My Drive/dataset/',100)\n",
        "\n",
        "print(\"Preprocessing Phase 1 : Finished\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y6ZaIBkEqh-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxval, minval = 0, 999999\n",
        "for doc in X:\n",
        "  for sentence in doc:\n",
        "    minval = min(minval, len(sentence))\n",
        "    maxval = max(maxval, len(sentence))\n",
        "print(maxval, minval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dogCj1qYc2nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Labels = np.unique(Y, return_counts = True)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "piwDLTFRdl06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LabelCount = {}\n",
        "for label in Labels:\n",
        "  LabelCount[label] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Gza3XQhddg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MIN_VAL = min(np.unique(Y,return_counts=True)[1]) + 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "96JydSd3ees2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dataBalancing(X, Y, LabelCount, MIN_VAL):\n",
        "  X_data = []\n",
        "  for i in range(len(X)):\n",
        "      if(LabelCount[Y[i]] < MIN_VAL):\n",
        "          X_data.append([X[i],Y[i]])\n",
        "          LabelCount[Y[i]] += 1\n",
        "\n",
        "  random.shuffle(X_data)\n",
        "\n",
        "  new_X = []\n",
        "  new_Y = []\n",
        "  for m ,n in X_data:\n",
        "    new_X.append(m)\n",
        "    new_Y.append(n)\n",
        "\n",
        "  return new_X, new_Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDd4A2t4fCJ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, Y = dataBalancing(X, Y, LabelCount, MIN_VAL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kUx8rP-nVUJX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tag_to_index_dictionary(X):\n",
        "    tag = set([])\n",
        "    for doc in X:\n",
        "        for sentence in doc:\n",
        "            for word in sentence:\n",
        "                tag.add(word)\n",
        "    tag2index = {t: i + 1 for i, t in enumerate(list(tag))}\n",
        "    tag2index['-PAD-'] = 0\n",
        "    return tag2index\n",
        "\n",
        "def convert_tag_to_sequence_numbers(X, tag2index):\n",
        "    new_X=[]\n",
        "    for doc in X:\n",
        "        new_S = []\n",
        "        for sentence in doc:\n",
        "            new_W = []\n",
        "            for word in sentence:\n",
        "                new_W.append(tag2index[word])\n",
        "            new_S.append(new_W)\n",
        "        new_X.append(new_S)\n",
        "    return new_X\n",
        "\n",
        "\n",
        "def pad_zeros_to_sequence(X, max_length):\n",
        "    new_X = []\n",
        "    for doc in X:\n",
        "        new_X.append(pad_sequences(doc, maxlen=max_length, padding='post'))\n",
        "    return new_X\n",
        "\n",
        "def Encode_Labels(Y):\n",
        "    le = LabelEncoder()\n",
        "    return le.fit_transform(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zpl-BmOWFsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tag2index = tag_to_index_dictionary(X)\n",
        "DICTIONARY_LENGTH = len(tag2index)\n",
        "MAX_LENGTH = 30 # why 30 only ?\n",
        "SENTENCES_IN_NOVEL = 100\n",
        "\n",
        "X = convert_tag_to_sequence_numbers(X, tag2index)\n",
        "X = pad_zeros_to_sequence(X, MAX_LENGTH)\n",
        "X = np.array(X)\n",
        "TOTAL_ROWS = X.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOft0pgkr32P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}